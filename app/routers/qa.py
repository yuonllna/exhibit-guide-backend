from fastapi import APIRouter, Depends, Request, HTTPException, UploadFile, File
from sentence_transformers import SentenceTransformer
import numpy as np

from app.schemas.qa import Question, Answer
from app.services.speech.stt import SpeechToTextService
from app.services.embedding.searcher import search
from app.services.llm.gemini_client import GeminiClient

router = APIRouter()

def get_encoder(request: Request) -> SentenceTransformer:
    return request.app.state.encoder

def get_index_docs(request: Request):
    return request.app.state.index, request.app.state.documents

def get_llm(request: Request) -> GeminiClient:
    return request.app.state.gemini

@router.post("/artifacts/questions", response_model=Answer)
async def ask_question_by_voice(
    file: UploadFile = File(...),
    encoder: SentenceTransformer = Depends(get_encoder),
    idx_docs = Depends(get_index_docs),
    llm: GeminiClient = Depends(get_llm),
):
    index, documents = idx_docs

    # 1) ìŒì„± íŒŒì¼ ë¡œë“œ
    if file.content_type not in ["audio/wav", "audio/x-wav", "audio/webm"]:
        raise HTTPException(status_code=400, detail="WAV ë˜ëŠ” WebM í˜•ì‹ë§Œ ì§€ì›ë©ë‹ˆë‹¤.")

    audio_content = await file.read()

    # 2) Google stt
    stt_service = SpeechToTextService()
    try:
        question_text = stt_service.transcribe(audio_content)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

    print(f"[ğŸ™ï¸ STT ë³€í™˜ ê²°ê³¼] {question_text}")

    # 3) ì§ˆë¬¸ ì„ë² ë”©
    q_vec = encoder.encode([question_text]).astype("float32")

    # 4) ìƒìœ„ kê°œ ë¬¸ì„œ ê²€ìƒ‰
    k = 3
    D, I = search(index, q_vec, k=k)

    # 5) ìœ ì‚¬ë„ í•„í„°ë§
    threshold = 0.5
    filtered_docs = [
        (documents[i], D[0][rank])
        for rank, i in enumerate(I[0])
        if D[0][rank] < threshold
    ]

    if not filtered_docs:
        print("[ğŸ“­ ìœ ì‚¬í•œ ë¬¸ì„œ ì—†ìŒ] ì»¨í…ìŠ¤íŠ¸ ì—†ì´ LLM í˜¸ì¶œ")
        answer_text = llm.answer("", question_text)
        print(answer_text)
        return Answer(
            question=question_text,
            gemini_answer=answer_text,
        )
    
    # 6) ìµœëŒ€ 3ê°œ ë¬¸ì„œ ì¶”ì¶œ
    top_docs = [doc for doc, _ in filtered_docs[:3]]
    combined_text = "\n\n".join([f"- {doc['text']}" for doc in top_docs])

    # 7) Gemini í˜¸ì¶œ
    answer_text = llm.answer(combined_text, question_text)

    print("\n[ğŸ” Gemini RAG ê²€ìƒ‰ ê²°ê³¼]")
    for i, doc in enumerate(top_docs):
        print(f"[{i+1}] ID: {doc['id']}")
        print(f"Text: {doc['text']}\n")

    return Answer(
        question=question_text,
        gemini_answer=answer_text,
    )